1. Cite 5 diferenças entre o AdaBoost e o GBM.

    - O AdaBoost é uma floresta de stumps e o GBM de stumps
    - no Adaboos o primeiro passo é um stump, no GBA o primeiro passo é a média do Y
    - no adaBoost cada resposta tem um peso diferente, no GBM todas as respostas das árvores possuem um multiplicador em comum chamado de `learning_rate` ou eta.
    - o AdaBoost utiliza a função de perda (*loss function*) exponencial que pode tornar o modelo sensível a **outlier**, enquanto o GBM pode utilizar qualquer *loss function*.
    - o GBM pode ser utlizado para resolver problemas diferenciáveis enquanto o AdaBoost foi criado para resolver problemas binários.

2. Acesse o link Scikit-learn – GBM, leia a explicação
(traduza se for preciso) e crie um jupyter notebook
contendo o exemplo de classificação e de regressão
do GBM.

3. Cite 5 Hyperparametros importantes no GBM.
    - loss: determina a *loss function*
    - learning_rate
    - n_estimators
    - subsamples
    - criterion
    
4. (Opcional) Utilize o GridSearch para encontrar os
melhores hyperparametros para o conjunto de dados
do exemplo

5. Acessando o artigo do Jerome Friedman (Stochastic) e
pensando no nome dado ao Stochastic GBM, qual é a
maior diferença entre os dois algoritmos?